# ğŸ—ï¸ Arquitectura Background Tasks - Adelanta Backend Toolbox

> **ğŸ”§ Basado en Celery**: Esta arquitectura utiliza Celery como motor de tareas asÃ­ncronas distribuidas, proporcionando escalabilidad y confiabilidad para procesamiento en background.

## ğŸ“‹ **Ãndice**

1. [ğŸ“ Estructura de Carpetas](#-estructura-de-carpetas)
2. [ğŸ”„ Flujo de Responsabilidades](#-flujo-de-responsabilidades)
3. [ğŸ“‹ PatrÃ³n de ImplementaciÃ³n](#-patrÃ³n-de-implementaciÃ³n)
4. [ğŸ¯ Principios de Arquitectura](#-principios-de-arquitectura-actualizados)
    - [âœ… PatrÃ³n EstÃ¡ndar para Endpoints /execute](#-patrÃ³n-estÃ¡ndar-para-endpoints-execute)
    - [âœ… DetecciÃ³n AutomÃ¡tica de Tasks](#-detecciÃ³n-automÃ¡tica-de-tasks)
    - [âœ… ConfiguraciÃ³n de ImportaciÃ³n](#-configuraciÃ³n-de-importaciÃ³n)
5. [ğŸš€ Comandos de EjecuciÃ³n](#-comandos-de-ejecuciÃ³n)
6. [ğŸ§ª Testing](#-testing)
7. [ğŸ“š Convenciones de Nomenclatura](#-convenciones-de-nomenclatura)
8. [ğŸ› ï¸ Troubleshooting y GuÃ­as](#-troubleshooting-y-guÃ­as)

## ğŸ“ **Estructura de Carpetas**

```bash
adelanta-backend-toolbox/
â”œâ”€â”€ models/          # ORM Models (SQLAlchemy)
â”œâ”€â”€ repositories/    # Acceso a datos
â”œâ”€â”€ services/        # LÃ³gica de negocio
â”œâ”€â”€ routers/         # Endpoints FastAPI
â”œâ”€â”€ schemas/         # ValidaciÃ³n Pydantic
â”œâ”€â”€ config/          # Configuraciones
â”‚   â””â”€â”€ celery_config.py      # âœ… Solo configuraciÃ³n Celery
â”œâ”€â”€ background/               # ğŸ†• Todo lo relacionado con Celery
â”‚   â”œâ”€â”€ tasks/                # ğŸ“‹ Tasks organizadas por dominio
â”‚   â”‚   â””â”€â”€ toolbox/         # ğŸ§° Tasks de toolbox
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ kpi_acumulado_task.py
â”‚   â”‚       â”œâ”€â”€ tablas_reportes_task.py
â”‚   â”‚       â”œâ”€â”€ tablas_cxc_task.py
â”‚   â”‚       â”œâ”€â”€ etl_task.py
â”‚   â”‚       â”œâ”€â”€ tipo_cambio_task.py
â”‚   â”‚       â””â”€â”€ ... (A-Z tasks)
â”‚   â”œâ”€â”€ processors/           # ğŸ§  LÃ³gica de negocio pura
â”‚   â”‚   â”œâ”€â”€ base_processor.py         # ğŸ†• Clase base con get_task_status() centralizada
â”‚   â”‚   â””â”€â”€ toolbox/         # ğŸ§° Processors de toolbox
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ kpi_acumulado_processor.py
â”‚   â”‚       â”œâ”€â”€ tablas_reportes_processor.py
â”‚   â”‚       â”œâ”€â”€ tablas_cxc_processor.py
â”‚   â”‚       â”œâ”€â”€ etl_processor.py
â”‚   â”‚       â”œâ”€â”€ tipo_cambio_processor.py
â”‚   â”‚       â””â”€â”€ ... (A-Z processors)
â”‚   â”œâ”€â”€ routers/              # ğŸ® API Endpoints especÃ­ficos de Background
â”‚   â”‚   â”œâ”€â”€ base_router.py            # ğŸ†• Router central: /status/{task_id} y /available
â”‚   â”‚   â””â”€â”€ toolbox/         # ğŸ§° Routers de toolbox
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ kpi_acumulado_router.py
â”‚   â”‚       â”œâ”€â”€ tablas_reportes_router.py
â”‚   â”‚       â”œâ”€â”€ tablas_cxc_router.py
â”‚   â”‚       â””â”€â”€ ... (A-Z routers)
â”‚   â””â”€â”€ schemas/              # ğŸ“‹ Schemas especÃ­ficos de Background
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ task_schema.py    # ğŸ”„ Schemas genÃ©ricos para tasks
â””â”€â”€ pytest/
```

## ğŸ”„ **Flujo de Responsabilidades**

```mermaid
graph TD
    A[Router] --> B[Celery Task]
    B --> C[Business Logic Function]
    C --> D[Repository Factory]
    D --> E[Database]
```

### **1. Router (API Endpoints)**

-   **UbicaciÃ³n**: `background/routers/toolbox/`
-   **Responsabilidad**: Exponer endpoints HTTP especÃ­ficos de Background Tasks
-   **Ejemplo**: `POST /tasks/execute/kpi-acumulado`

### **2. Celery Task (OrquestaciÃ³n + Business Logic)**

-   **UbicaciÃ³n**: `background/tasks/toolbox/`
-   **Responsabilidad**: Task de Celery + LÃ³gica de negocio completa
-   **CaracterÃ­sticas**: Manejo de errores Celery, retries, serializaciÃ³n + Business Logic

### **3. Repository Factory (Acceso a Datos)**

-   **UbicaciÃ³n**: `config/repository_factory.py`
-   **Responsabilidad**: Crear repositories con sesiones aisladas para Celery
-   **CaracterÃ­sticas**: Pool optimizado, cleanup automÃ¡tico

### **4. Processor (OPCIONAL - Solo Wrapper)**

-   **UbicaciÃ³n**: `background/processors/toolbox/`
-   **Responsabilidad**: Wrapper de compatibilidad (NO lÃ³gica de negocio)
-   **CaracterÃ­sticas**: Solo llama al Task de Celery, mantiene interfaz original
-   **BaseProcessor**: Clase base con lÃ³gica centralizada de `get_task_status()` y formateo

## ğŸ“‹ **PatrÃ³n de ImplementaciÃ³n**

### **Task (Business Logic + Celery)**

```python
# background/tasks/toolbox/kpi_acumulado_task.py
from config.repository_factory import create_repository_factory

@celery_app.task(name="toolbox.kpi_acumulado", bind=True, max_retries=0)
def kpi_acumulado_task(self):
    """ğŸ“‹ Task con lÃ³gica de negocio completa"""
    try:
        result = asyncio.run(_actualizar_kpi_acumulado_logic())
        return {"status": "success", "records": result.get("records", 0)}
    except Exception as e:
        return {"status": "failed", "error": str(e)}

async def _actualizar_kpi_acumulado_logic():
    """LÃ³gica de negocio usando repository_factory"""
    repo_factory = create_repository_factory()
    try:
        tipo_cambio_repo = await repo_factory.create_tipo_cambio_repository()
        # ... lÃ³gica de negocio aquÃ­
        return {"records": len(results)}
    finally:
        await repo_factory.cleanup()
```

### **Repository Factory (Acceso a Datos)**

```python
# config/repository_factory.py
class RepositoryFactory:
    """Factory para crear repositories con sesiones aisladas"""

    async def create_tipo_cambio_repository(self):
        session = await self.get_db_session()
        return TipoCambioRepository(session)

    async def cleanup(self):
        """Limpiar recursos"""
        if self._session:
            await self._session.close()
```

### **Router (API Wrapper)**

```python
# background/routers/base_router.py - Router centralizado
@router.get("/status/{task_id}")
async def get_status(task_id: str):
    """ğŸ¯ Status centralizado para cualquier task"""
    return BaseProcessor.format_task_response(task_id)

@router.get("/available")
async def list_available_tasks():
    """ğŸ“‹ Lista automÃ¡tica de todas las tasks disponibles"""
    return BaseProcessor.get_available_tasks()

# background/routers/toolbox/kpi_acumulado_router.py - Router especÃ­fico
@router.post(
    "/execute",
    response_model=TaskExecuteResponse,
    response_class=ORJSONResponse,
    summary="ğŸš€ Ejecutar [Nombre Task]",
    description="Ejecuta la actualizaciÃ³n de [descripciÃ³n] usando Celery",
)
async def execute_task():
    """ï¿½ Control remoto para ejecutar [Task] bajo demanda"""
    try:
        logger.info("ï¿½ğŸ® API: Iniciando ejecuciÃ³n remota de [Task]...")

        # Instanciar el wrapper de Celery
        processor = TaskProcessor()

        # Ejecutar task
        result = await processor.run()

        logger.info(f"âœ… API: Task enviada exitosamente - ID: {result['task_id']}")

        return TaskExecuteResponse(
            success=True,
            task_id=result["task_id"],
            message="Task [nombre] enviada a Celery exitosamente",
            task_name="nombre_task",
        )

    except Exception as e:
        logger.error(f"âŒ API: Error ejecutando [Task]: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error ejecutando task: {str(e)}")
```

### **Processor (OPCIONAL - Solo Wrapper)**

```python
# background/processors/base_processor.py
class BaseProcessor:
    """ğŸ”„ Clase base con lÃ³gica centralizada para Celery task status"""

    def get_task_status(self, task_id: str) -> Dict[str, Any]:
        """LÃ³gica centralizada para obtener estado de Celery tasks"""

    @staticmethod
    def format_task_response(task_id: str) -> TaskStatusResponse:
        """MÃ©todo estÃ¡tico para formatear respuestas desde routers directos"""

# background/processors/toolbox/kpi_acumulado_processor.py
class KPIAcumuladoProcessor(BaseProcessor):
    """ğŸ”„ Wrapper de compatibilidad - hereda get_task_status()"""

    async def run(self):
        """Solo llama al task de Celery"""
        result = kpi_acumulado_task.delay()
        return {"status": "enqueued", "task_id": result.id}
```

### **Schemas (ValidaciÃ³n)**

```python
# background/schemas/task_schema.py
class TaskExecuteResponse(BaseModel):
    success: bool
    task_id: str
    message: str
    task_name: str

class TaskStatusResponse(BaseModel):
    task_id: str
    status: str
    result: Optional[Any] = None
    ready: bool
    successful: Optional[bool] = None
    failed: Optional[bool] = None
    error: Optional[str] = None
```

## ğŸ¯ **Principios de Arquitectura ACTUALIZADOS**

### **âœ… PATRÃ“N ESTÃNDAR PARA ENDPOINTS /execute**

**ğŸ¯ Estructura Obligatoria para todos los routers:**

```python
@router.post(
    "/execute",
    response_model=TaskExecuteResponse,
    response_class=ORJSONResponse,
    summary="ğŸš€ Ejecutar [Nombre Task]",
    description="Ejecuta la actualizaciÃ³n de [descripciÃ³n especÃ­fica] usando Celery",
)
async def execute_[nombre]_task():
    """ğŸ¯ Control remoto para ejecutar [Task] bajo demanda"""
    try:
        logger.info("ğŸ® API: Iniciando ejecuciÃ³n remota de [Task]...")

        # Instanciar el wrapper de Celery
        processor = [TaskName]Processor()

        # Ejecutar task
        result = await processor.run()

        logger.info(f"âœ… API: Task enviada exitosamente - ID: {result['task_id']}")

        return TaskExecuteResponse(
            success=True,
            task_id=result["task_id"],
            message="Task [nombre] enviada a Celery exitosamente",
            task_name="[nombre]_task",
        )

    except Exception as e:
        logger.error(f"âŒ API: Error ejecutando [Task]: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error ejecutando task: {str(e)}")
```

**ğŸ“‹ Elementos Obligatorios:**

-   âœ… `response_class=ORJSONResponse` - Performance optimizada
-   âœ… `summary` y `description` descriptivos con emojis
-   âœ… Logging detallado de inicio y resultado
-   âœ… Try/catch robusto con HTTPException
-   âœ… Uso del Processor correspondiente (no task directo)
-   âœ… Formateo consistente del TaskExecuteResponse

### **âœ… DETECCIÃ“N AUTOMÃTICA DE TASKS**

**ğŸ¯ Sistema de Auto-Discovery:**

-   **ANTES**: Lista manual de tasks en cada router â†’ duplicaciÃ³n de cÃ³digo
-   **DESPUÃ‰S**: DetecciÃ³n automÃ¡tica desde registro de Celery â†’ sin duplicaciÃ³n

**ğŸ”§ ImplementaciÃ³n en BaseProcessor:**

```python
@staticmethod
def get_available_tasks() -> Dict[str, Any]:
    """
    ğŸ¯ DetecciÃ³n automÃ¡tica de tasks desde registro de Celery
    âœ… Multi-patrÃ³n: busca 'toolbox.', 'background.'
    âœ… Logging detallado + manejo robusto de errores
    âœ… Fallback automÃ¡tico a lista manual
    """
    try:
        registered_tasks = celery_app.tasks
        background_task_patterns = ["toolbox.", "background."]

        # Filtrar tasks de background
        background_tasks = {
            name: task for name, task in registered_tasks.items()
            if any(name.startswith(pattern) for pattern in background_task_patterns)
            and not name.startswith("celery.")
        }

        # Procesar cada task para generar metadata
        available_tasks = {}
        for task_name, task_obj in background_tasks.items():
            clean_name = task_name.replace("toolbox.", "").replace("background.", "")
            endpoint = f"/tasks/execute/{clean_name.replace('_', '-')}"

            available_tasks[clean_name] = {
                "name": task_name,
                "description": extract_description(task_obj),
                "endpoint": endpoint,
                "method": "POST",
                "module": getattr(task_obj, "__module__", "Unknown"),
            }

        return {
            "success": True,
            "available_tasks": available_tasks,
            "total_tasks": len(available_tasks),
            "auto_generated": True,
        }
    except Exception as e:
        # Fallback automÃ¡tico a lista manual
        return BaseProcessor._get_manual_tasks_list()
```

**ğŸ“Š Respuesta API /tasks/available:**

```json
{
    "success": true,
    "available_tasks": {
        "kpi_acumulado": {
            "name": "toolbox.kpi_acumulado",
            "description": "ğŸ¯ Task Celery: Actualizar KPI Acumulado",
            "endpoint": "/tasks/execute/kpi-acumulado",
            "method": "POST",
            "module": "background.tasks.toolbox.kpi_acumulado_task"
        },
        "kpi": {
            "name": "toolbox.kpi",
            "description": "Actualiza tablas de reportes",
            "endpoint": "/tasks/execute/kpi",
            "method": "POST",
            "module": "background.tasks.toolbox.kpi_task"
        }
    },
    "total_tasks": 4,
    "auto_generated": true
}
```

### **âœ… CONFIGURACIÃ“N DE IMPORTACIÃ“N**

**ğŸ”§ Celery Config Actualizado:**

```python
# config/celery_config.py
celery_app = Celery(
    "adelanta-toolbox",
    include=[
        "background.tasks.toolbox",  # ğŸ†• Tasks del directorio background
        "config.celery_tasks",       # Legacy para compatibilidad
    ],
)
```

**ğŸ“‹ Import Centralizado:**

```python
# background/tasks/toolbox/__init__.py
from .kpi_acumulado_task import actualizar_kpi_acumulado_task
from .kpi_task import actualizar_tablas_reportes_task
from .tablas_reportes_task import tablas_reportes_task
from .tablas_cxc_task import tablas_cxc_task

__all__ = [
    "actualizar_kpi_acumulado_task",
    "actualizar_tablas_reportes_task",
    "tablas_reportes_task",
    "tablas_cxc_task",
]
```

### **âœ… DECISIÃ“N FINAL: Tasks Con LÃ³gica de Negocio**

-   **Tasks**: Contienen toda la lÃ³gica de negocio + orquestaciÃ³n Celery
-   **Repository Factory**: Maneja acceso a datos con sesiones aisladas
-   **Routers**: Solo endpoints HTTP que llaman a Tasks
-   **Processors**: OPCIONALES - Solo wrappers de compatibilidad (NO lÃ³gica de negocio)

### **âœ… PatrÃ³n Repository Factory**

-   **NO usar `@inject`**: Usar `repository_factory` en su lugar
-   **Sesiones aisladas**: Cada task tiene sus propios repositories
-   **Cleanup automÃ¡tico**: `finally` block para limpiar recursos
-   **Pool optimizado**: ConfiguraciÃ³n especÃ­fica para Celery

### **âœ… Estructura Simplificada**

```bash
background/
â”œâ”€â”€ tasks/           # ğŸ“‹ Celery Tasks CON lÃ³gica de negocio
â”œâ”€â”€ routers/         # ğŸ® API Endpoints (llaman a tasks o BaseProcessor.format_task_response)
â”œâ”€â”€ processors/      # ğŸ”„ OPCIONAL: Wrappers de compatibilidad (heredan de BaseProcessor)
â”‚   â””â”€â”€ base_processor.py  # ğŸ†• LÃ³gica centralizada get_task_status() + formateo
â””â”€â”€ schemas/         # ğŸ“‹ Schemas de validaciÃ³n
```

### **âœ… PatrÃ³n BaseProcessor Centralizado**

-   **BaseProcessor**: Centraliza `get_task_status()` y formateo de respuestas
-   **Herencia**: Todos los processors heredan de BaseProcessor
-   **MÃ©todo estÃ¡tico**: `BaseProcessor.format_task_response()` para routers directos
-   **EliminaciÃ³n duplicaciÃ³n**: ~150 lÃ­neas de cÃ³digo duplicado eliminadas

## ğŸ¯ **Flujo Centralizado ACTUALIZADO**

### **OpciÃ³n A: Router con Processor (KPI Acumulado)**

```python
# background/routers/toolbox/kpi_acumulado_router.py
@router.get("/status/{task_id}")
async def get_status(task_id: str):
    processor = KPIAcumuladoProcessor()
    return processor.get_formatted_task_status(task_id)  # ğŸ“‹ Formateo centralizado
```

### **OpciÃ³n B: Router Directo (Tablas Reportes/CXC)**

```python
# background/routers/toolbox/tablas_reportes_router.py
@router.get("/status/tablas-reportes/{task_id}")
async def get_status(task_id: str):
    return BaseProcessor.format_task_response(task_id)  # ğŸ“‹ MÃ©todo estÃ¡tico centralizado
```

### **âœ… Beneficios de la CentralizaciÃ³n**

-   **ğŸ“Š Consistencia**: Mismo formato de respuesta entre todos los endpoints
-   **ğŸ”§ Mantenibilidad**: Un solo lugar para modificar lÃ³gica de status
-   **ğŸ“‰ DuplicaciÃ³n**: Eliminadas ~150 lÃ­neas de cÃ³digo duplicado
-   **ğŸ›¡ï¸ Robustez**: Manejo de errores unificado y robusto
-   **ğŸ¤– AutomatizaciÃ³n**: Lista de tasks extraÃ­da automÃ¡ticamente desde celery_app
-   **ğŸ”„ Fallback**: Sistema de respaldo manual en caso de errores

### **ğŸ¤– AutomatizaciÃ³n de Tasks**

```python
# MÃ©todo automatizado en BaseProcessor
@staticmethod
def get_available_tasks():
    """Extrae automÃ¡ticamente tasks desde celery_app.tasks"""
    registered_tasks = celery_app.tasks
    background_tasks = {
        name: task for name, task in registered_tasks.items()
        if name.startswith('toolbox.') or name.startswith('background.')
    }
    # Procesa automÃ¡ticamente: name, description, endpoint, module
```

### **ğŸ“ Endpoints Centralizados**

```bash
# ANTES: Duplicados en cada router
/toolbox/status/{task_id}           # En cada router especÃ­fico
/toolbox/available                  # En cada router especÃ­fico

# DESPUÃ‰S: Centralizados en base_router
/tasks/status/{task_id}             # âœ… Centralizado - funciona para cualquier task
/tasks/available                    # âœ… Centralizado - lista automÃ¡tica desde Celery
```

## ğŸš€ **Comandos de EjecuciÃ³n**

### **Desarrollo**

```bash
# Ejecutar worker
uv run celery -A config.celery_config worker --loglevel=info --queues=cronjobs,default

# Ejecutar scheduler
uv run celery -A config.celery_config beat --loglevel=info
```

### **API Endpoints**

```bash
# Ejecutar task
POST /tasks/execute/kpi-acumulado

# Consultar estado
GET /tasks/status/{task_id}

# Listar tasks disponibles
GET /tasks/available
```

## ğŸ§ª **Testing**

### **Test Processor (Sin Celery)**

```python
def test_kpi_processor():
    processor = KPIAcumuladoProcessor()
    result = asyncio.run(processor.process())
    assert result["records"] > 0
```

### **Test Task (Con Celery)**

```python
def test_kpi_task():
    result = kpi_acumulado_task()
    assert result["status"] == "success"
```

## ğŸ“š **Convenciones de Nomenclatura**

### **Archivos y Clases**

-   **Task**: `kpi_acumulado_task.py` â†’ `kpi_acumulado_task()`
-   **Processor**: `kpi_acumulado_processor.py` â†’ `KPIAcumuladoProcessor`
-   **Router**: `kpi_acumulado_router.py` â†’ endpoints relacionados
-   **Schema**: `task_schema.py` â†’ schemas genÃ©ricos para tasks

### **Imports**

```python
# âœ… CORRECTO - Sin conflicto con librerÃ­a celery
from background.tasks.toolbox.kpi_acumulado_task import kpi_acumulado_task
from background.processors.toolbox.kpi_acumulado_processor import KPIAcumuladoProcessor
from background.routers.toolbox.kpi_acumulado_router import router
from background.schemas.task_schema import TaskExecuteResponse, TaskStatusResponse

# âœ… CORRECTO - LibrerÃ­a externa
from celery import Celery
import celery
```

## ğŸ¯ **MigraciÃ³n Actual â†’ Nueva Estructura CORREGIDA**

### **Mapeo de Archivos**

```bash
# ANTES:
cronjobs/datamart/ActualizarTablasReportesCronjob.py  # Con @inject
cronjobs/datamart/ActualizarTablasCXCCronjob.py       # Con @inject

# DESPUÃ‰S:
background/tasks/toolbox/tablas_reportes_task.py     # Con repository_factory + lÃ³gica completa
background/tasks/toolbox/tablas_cxc_task.py          # Con repository_factory + lÃ³gica completa
background/routers/toolbox/tablas_reportes_router.py # API endpoints
background/routers/toolbox/tablas_cxc_router.py      # API endpoints
background/processors/toolbox/tablas_reportes_processor.py # OPCIONAL: Solo wrapper
background/processors/toolbox/tablas_cxc_processor.py     # OPCIONAL: Solo wrapper
```

### **PatrÃ³n de MigraciÃ³n**

1. **Copiar lÃ³gica original** â†’ `background/tasks/toolbox/xxx_task.py`
2. **Reemplazar `@inject`** â†’ `repository_factory`
3. **Agregar Celery wrapper** â†’ `@celery_app.task`
4. **Crear API endpoints** â†’ `background/routers/toolbox/xxx_router.py`
5. **Processor OPCIONAL** â†’ Solo si necesitas compatibilidad

### **Beneficios de la Nueva Estructura**

-   âœ… **Sin conflictos**: `background/` vs `celery` librerÃ­a
-   âœ… **Repository Factory**: Sesiones aisladas y cleanup automÃ¡tico
-   âœ… **Tasks completos**: LÃ³gica de negocio + Celery en un lugar
-   âœ… **Menos capas**: Eliminamos complejidad innecesaria
-   âœ… **Mantenible**: PatrÃ³n directo y predecible

---

## ğŸ’¡ **Resumen Ejecutivo**

La carpeta `background/` contiene toda la infraestructura para tareas asÃ­ncronas:

-   **`tasks/`**: Definiciones de Celery (thin wrappers)
-   **`processors/`**: LÃ³gica de negocio pura (independiente de Celery)
-   **`routers/`**: API Endpoints especÃ­ficos de Background Tasks
-   **`schemas/`**: Schemas genÃ©ricos para validaciÃ³n de tasks
-   **OrganizaciÃ³n por dominio**: `toolbox/`, `datamart/`, etc.
-   **Sin conflictos**: Evita choques con la librerÃ­a `celery`

## ğŸ› ï¸ **Troubleshooting y GuÃ­as**

### **âŒ Task no aparece en /tasks/available**

**1. Verificar importaciÃ³n en `__init__.py`:**

```python
# background/tasks/toolbox/__init__.py
from .nueva_task import nueva_task_function  # âœ… Agregar esta lÃ­nea
```

**2. Verificar decorador de task:**

```python
@celery_app.task(name="toolbox.nueva_task")  # âœ… Prefijo correcto
def nueva_task_function():
    pass
```

**3. Verificar include en Celery:**

```python
# config/celery_config.py
include=["background.tasks.toolbox"]  # âœ… Debe estar presente
```

### **ğŸ”§ Agregar Nueva Task (Paso a Paso)**

```bash
# 1. Crear archivo de task
touch background/tasks/toolbox/nueva_task.py

# 2. Implementar task
# background/tasks/toolbox/nueva_task.py
@celery_app.task(name="toolbox.nueva_task")
def nueva_task():
    """ğŸ¯ Description of new task"""
    return {"status": "success"}

# 3. Agregar import
# background/tasks/toolbox/__init__.py
from .nueva_task import nueva_task

# 4. Â¡AUTOMÃTICO! - AparecerÃ¡ en /tasks/available
```

### **ğŸ¯ Crear Router para Nueva Task**

```python
# background/routers/toolbox/nueva_router.py
@router.post(
    "/execute",
    response_model=TaskExecuteResponse,
    response_class=ORJSONResponse,
    summary="ğŸš€ Ejecutar Nueva Task",
    description="Ejecuta nueva funcionalidad usando Celery",
)
async def execute_nueva_task():
    """ğŸ¯ Control remoto para ejecutar Nueva Task bajo demanda"""
    try:
        logger.info("ğŸ® API: Iniciando ejecuciÃ³n remota de Nueva Task...")

        # Instanciar processor
        processor = NuevaTaskProcessor()
        result = await processor.run()

        logger.info(f"âœ… API: Task enviada exitosamente - ID: {result['task_id']}")

        return TaskExecuteResponse(
            success=True,
            task_id=result["task_id"],
            message="Task Nueva enviada a Celery exitosamente",
            task_name="nueva_task",
        )
    except Exception as e:
        logger.error(f"âŒ API: Error ejecutando Nueva Task: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error ejecutando task: {str(e)}")
```

### **ğŸ“Š Debug de Tasks**

```python
# Ver todas las tasks registradas
from config.celery_config import celery_app
print(list(celery_app.tasks.keys()))

# Ver informaciÃ³n de debug
response = BaseProcessor.get_available_tasks()
print(response.get("debug_info", {}))
```

### **ğŸš€ Para Futuras Implementaciones**

**âœ… Ventajas del Sistema Actual:**

1. **ğŸ”„ Auto-Discovery**: Nuevas tasks se detectan automÃ¡ticamente
2. **ğŸ›¡ï¸ Robusto**: Manejo de errores y fallback manual
3. **ğŸ“Š Observable**: Logging detallado y debug info
4. **ğŸ§¹ Sin DuplicaciÃ³n**: Elimina listas manuales en routers
5. **âš¡ Performance**: Genera endpoints dinÃ¡micamente
6. **ğŸ”§ Flexible**: Patrones configurables para diferentes prefijos

**ğŸ“ Estado Actual:**

-   âœ… **4 Tasks Detectadas**: `kpi_acumulado`, `kpi`, `tablas_reportes`, `tablas_cxc`
-   âœ… **AutomatizaciÃ³n Completa**: Sin listas manuales en routers
-   âœ… **Fallback Funcional**: Sistema robusto ante fallos
-   âœ… **Endpoints Centralizados**: `/tasks/status` y `/tasks/available`

Esta arquitectura garantiza **escalabilidad**, **mantenibilidad** y **testabilidad** para el crecimiento futuro del proyecto.
