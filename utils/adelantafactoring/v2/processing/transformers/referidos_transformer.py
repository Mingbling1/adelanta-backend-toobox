"""
ğŸ”„ Referidos Transformer V2 - Adelanta Factoring Financial ETL

Transformador especializado para el procesamiento completo de datos de referidos.
Implementa el patrÃ³n Calculator â†’ Obtainer â†’ Schema de forma optimizada.
"""

import pandas as pd
from typing import Union, List, Dict, Tuple
from config.logger import logger
from ...engines.referidos_data_engine import ReferidosDataEngine
from ...engines.referidos_validation_engine import ReferidosValidationEngine
from ...schemas.referidos import ReferidosProcessedSchema


class ReferidosTransformer:
    """
    ğŸš€ Transformador principal para datos de referidos.

    CaracterÃ­sticas:
    - ğŸ”„ Pipeline ETL completo: Extract â†’ Transform â†’ Load
    - âš¡ Optimizado con Pydantic RUST y list comprehensions
    - ğŸ›¡ï¸ Manejo robusto de errores en cada etapa
    - ğŸ“Š Compatible 100% con ReferidosCalcular legacy
    """

    def __init__(self):
        self.data_engine = ReferidosDataEngine()
        self.validation_engine = ReferidosValidationEngine()
        self._processing_stats = {}

    def transform_referidos(
        self, as_df: bool = False
    ) -> Union[List[Dict], pd.DataFrame]:
        """
        ğŸ”„ Flujo principal de transformaciÃ³n de referidos.

        Replica exactamente la funcionalidad de ReferidosCalcular.calcular()
        con optimizaciones de rendimiento y mejor manejo de errores.

        Args:
            as_df: Si True devuelve DataFrame, si False devuelve lista de dicts

        Returns:
            Union[List[Dict], pd.DataFrame]: Datos transformados segÃºn as_df
        """
        try:
            logger.info("ğŸš€ Iniciando transformaciÃ³n completa de referidos...")

            # 1ï¸âƒ£ EXTRACT: Obtener datos RAW
            raw_data = self._extract_raw_data()

            # 2ï¸âƒ£ TRANSFORM: Validar y procesar
            processed_data = self._transform_and_validate(raw_data)

            # 3ï¸âƒ£ LOAD: Formatear salida
            result = self._format_output(processed_data, as_df)

            # ğŸ“Š Guardar estadÃ­sticas para auditorÃ­a
            self._save_processing_stats(raw_data, processed_data)

            logger.info("âœ… TransformaciÃ³n de referidos completada exitosamente")
            return result

        except Exception as e:
            logger.error(f"ğŸ’¥ Error crÃ­tico en transformaciÃ³n de referidos: {e}")
            raise

    async def transform_referidos_async(
        self, as_df: bool = False
    ) -> Union[List[Dict], pd.DataFrame]:
        """
        ğŸ”„ Flujo asÃ­ncrono de transformaciÃ³n de referidos.

        Args:
            as_df: Si True devuelve DataFrame, si False devuelve lista de dicts

        Returns:
            Union[List[Dict], pd.DataFrame]: Datos transformados segÃºn as_df
        """
        try:
            logger.info("ğŸš€ Iniciando transformaciÃ³n asÃ­ncrona de referidos...")

            # 1ï¸âƒ£ EXTRACT: Obtener datos RAW de forma asÃ­ncrona
            raw_data = await self.data_engine.extract_referidos_data_async()

            # 2ï¸âƒ£ TRANSFORM: Validar y procesar (sÃ­ncronos)
            processed_data = self._transform_and_validate(raw_data)

            # 3ï¸âƒ£ LOAD: Formatear salida
            result = self._format_output(processed_data, as_df)

            # ğŸ“Š Guardar estadÃ­sticas para auditorÃ­a
            self._save_processing_stats(raw_data, processed_data)

            logger.info("âœ… TransformaciÃ³n asÃ­ncrona de referidos completada")
            return result

        except Exception as e:
            logger.error(f"ğŸ’¥ Error crÃ­tico en transformaciÃ³n asÃ­ncrona: {e}")
            raise

    def _extract_raw_data(self) -> List[Dict]:
        """ğŸ“¥ Extrae datos RAW del webservice"""
        try:
            logger.info("ğŸ“¥ Extrayendo datos RAW de referidos...")
            raw_data = self.data_engine.extract_referidos_data()

            # ValidaciÃ³n bÃ¡sica de estructura
            validated_raw = self.data_engine.validate_raw_data(raw_data)

            logger.info(f"âœ… ExtracciÃ³n completada: {len(validated_raw)} registros")
            return validated_raw

        except Exception as e:
            logger.error(f"ğŸ’¥ Error en extracciÃ³n de datos RAW: {e}")
            raise

    def _transform_and_validate(self, raw_data: List[Dict]) -> List[Dict]:
        """ğŸ”„ Transforma y valida datos RAW"""
        try:
            logger.info("ğŸ”„ Transformando y validando datos...")

            # 1. Validar estructura y convertir a schema estandarizado
            validated_data = self.validation_engine.validate_raw_to_schema(raw_data)

            # 2. Eliminar duplicados por CodigoLiquidacion
            deduplicated_data, duplicates_count = (
                self.validation_engine.validate_and_deduplicate(validated_data)
            )

            logger.info(
                f"âœ… TransformaciÃ³n completada: {len(deduplicated_data)} registros Ãºnicos"
            )
            return deduplicated_data

        except Exception as e:
            logger.error(f"ğŸ’¥ Error en transformaciÃ³n y validaciÃ³n: {e}")
            raise

    def _format_output(
        self, processed_data: List[Dict], as_df: bool
    ) -> Union[List[Dict], pd.DataFrame]:
        """ğŸ“¤ Formatea la salida segÃºn el parÃ¡metro as_df"""
        try:
            if as_df:
                logger.info("ğŸ“Š Convirtiendo a DataFrame...")
                df = pd.DataFrame(processed_data)
                logger.info(
                    f"âœ… DataFrame creado: {len(df)} filas, {len(df.columns)} columnas"
                )
                return df
            else:
                logger.info("ğŸ“‹ Retornando lista de diccionarios...")
                return processed_data

        except Exception as e:
            logger.error(f"ğŸ’¥ Error en formateo de salida: {e}")
            raise

    def _save_processing_stats(self, raw_data: List[Dict], processed_data: List[Dict]):
        """ğŸ“Š Guarda estadÃ­sticas del procesamiento para auditorÃ­a"""
        self._processing_stats = {
            "raw_records": len(raw_data),
            "processed_records": len(processed_data),
            "validation_errors": len(self.validation_engine.validation_errors),
            "processing_efficiency": (
                len(processed_data) / len(raw_data) if raw_data else 0
            ),
        }

        logger.info(f"ğŸ“Š EstadÃ­sticas de procesamiento: {self._processing_stats}")

    def get_processing_stats(self) -> Dict:
        """ğŸ“Š Obtiene estadÃ­sticas del Ãºltimo procesamiento"""
        return self._processing_stats.copy()

    def get_validation_report(self) -> Dict:
        """ğŸ“‹ Obtiene reporte detallado de validaciÃ³n"""
        return self.validation_engine.get_validation_report()

    def get_detailed_processing_result(
        self, as_df: bool = False
    ) -> Tuple[Union[List[Dict], pd.DataFrame], ReferidosProcessedSchema]:
        """
        ğŸ” Obtiene resultado detallado con metadatos completos.

        Args:
            as_df: Si True devuelve DataFrame, si False devuelve lista de dicts

        Returns:
            Tuple: (datos_procesados, schema_con_metadatos)
        """
        try:
            logger.info("ğŸ” Generando resultado detallado con metadatos...")

            # Extraer y procesar datos
            raw_data = self._extract_raw_data()
            processed_data = self._transform_and_validate(raw_data)

            # Crear schema con metadatos
            duplicates_removed = len(raw_data) - len(processed_data)
            processed_schema = self.validation_engine.validate_final_output(
                processed_data, duplicates_removed
            )

            # Formatear salida principal
            formatted_output = self._format_output(processed_data, as_df)

            logger.info("âœ… Resultado detallado generado exitosamente")
            return formatted_output, processed_schema

        except Exception as e:
            logger.error(f"ğŸ’¥ Error generando resultado detallado: {e}")
            raise
